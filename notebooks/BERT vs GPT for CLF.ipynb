{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1ceb7-3ed7-49c5-8d86-75f05d5b9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_metric, load_dataset\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589b8a4-c8b5-464a-aad0-8c8e13054e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a constant SEED for reproducibility in random operations\n",
    "SEED = 42\n",
    "\n",
    "# Setting the seed for the random library to ensure consistent results\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dc0c4-8932-4889-975d-05160be113ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'star' is a column in our dataset and we want to convert it to a ClassLabel column\n",
    "# so we can stratify our samples.\n",
    "\n",
    "# Importing the ClassLabel module to represent categorical class labels\n",
    "from datasets import ClassLabel\n",
    "\n",
    "# Loading the 'app_reviews' dataset's training split into the 'dataset' variable\n",
    "dataset = load_dataset('app_reviews', split='train')\n",
    "\n",
    "# Converting the 'star' column in our dataset to a ClassLabel type\n",
    "# This allows for categorical representation and easier handling of classes\n",
    "dataset = dataset.class_encode_column('star')\n",
    "\n",
    "# Displaying the dataset to see the changes\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe447c4-fc0e-4727-8538-aee1d4d2fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into a training set and a test set.\n",
    "# We reserve 20% of the data for testing and use stratification on the 'star' column\n",
    "# to ensure both sets have an equal distribution of each star category.\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED, stratify_by_column='star')\n",
    "\n",
    "# Now, we further split our training dataset to reserve 25% of it for validation.\n",
    "# Again, we stratify by the 'star' column to keep the distribution consistent.\n",
    "df = dataset['train'].train_test_split(test_size=.25, seed=SEED, stratify_by_column='star')\n",
    "\n",
    "# Assigning the split datasets to their respective keys:\n",
    "# - The remaining 75% of our initial training data becomes the new training dataset.\n",
    "dataset['train'] = df['train']\n",
    "\n",
    "# - The 25% split from our initial training data becomes the validation dataset.\n",
    "dataset['val'] = df['test']\n",
    "\n",
    "# Displaying the dataset to see the distribution across train, test, and validation sets.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c4761-bc78-408c-aa4d-21119b9779b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'distilbert-base-cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17e580-5916-450b-98da-c7c9b7474646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to batch tokenize utterances with truncation\n",
    "def preprocess_function(examples):  # each example is an element from the Dataset\n",
    "    return tokenizer(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17cad6-e4e9-4b10-ab03-7dd2e5e7d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626208d0-1e66-4559-a80b-f2888cc1a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728591b-2795-4bb3-b1a6-d83a31a51c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_clf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cd57d-d439-4432-b899-995dbc35d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a44187-d471-40f7-a47c-1df5e3083440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42374d-8e48-4b0e-88a7-87b801067855",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"star\", \"label\")\n",
    "dataset = dataset.remove_columns(['package_name', 'review', 'date'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278028c-193e-4cd6-b443-46eabfbe11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4136b95-d3e1-4b1a-861c-e92b6f44a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).mean()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d37f9-d732-4543-90c0-315bedf9415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_clf_results\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=32,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # some deep learning parameters that the Trainer is able to take in\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay = 0.05,\n",
    "    \n",
    "    logging_steps=1,\n",
    "    log_level='info',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=50,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['val'],\n",
    "    compute_metrics=compute_metrics,  # optional\n",
    "    data_collator=data_collator  # technically optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdefac-a0d4-435f-be2f-1287547b4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5824878-f25d-450b-8afd-81a3a0879abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_ids = dataset['train']['input_ids']\n",
    "pd.Series(input_ids).apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b86ef-3da5-4c58-a593-7c8386229d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e82c7-c91f-4120-ad3a-25838d72f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeca41f-9553-4b79-9d46-1ee2d9bdddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Test Set Evaluation Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f90ebb-f327-4823-9f91-8f357d144711",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513fba4-4640-430b-8c62-35e92fe39274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to gpt 3.5 and ada\n",
    "    # accuracy\n",
    "    # cost to train/host (on HF or make your own API)\n",
    "    # latency/throughput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e117977-822c-460a-8b91-462eb6d4a340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b7b6e-64f9-4da3-802f-f480c9045ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
