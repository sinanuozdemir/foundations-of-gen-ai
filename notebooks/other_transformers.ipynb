{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-retrieval",
   "metadata": {},
   "source": [
    "### NER: Named Enitty Recognition: Using token classification to classify entites from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/savasy/bert-base-turkish-ner-cased\n",
    "\n",
    "custom_module = 'savasy/bert-base-turkish-ner-cased'\n",
    "\n",
    "turkish_ner_tokenizer = AutoTokenizer.from_pretrained(custom_module)\n",
    "turkish_ner_model = AutoModelForTokenClassification.from_pretrained(custom_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unnecessary-bosnia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.724247,\n",
       "  'index': 5,\n",
       "  'word': 'Sinan',\n",
       "  'start': 20,\n",
       "  'end': 25},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99879956,\n",
       "  'index': 7,\n",
       "  'word': 'San',\n",
       "  'start': 27,\n",
       "  'end': 30},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99770975,\n",
       "  'index': 8,\n",
       "  'word': 'Francisco',\n",
       "  'start': 31,\n",
       "  'end': 40}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Merhaba! Benim adÄ±m Sinan. San Francisco'dan geliyorum\" # Hi! I'm Sinan. I come from San Francisco\"\n",
    "\n",
    "ner=pipeline('ner', model=turkish_ner_model, tokenizer=turkish_ner_tokenizer)\n",
    "ner(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-rating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "extreme-offer",
   "metadata": {},
   "source": [
    "### Speech Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-israeli",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WHAT A WONDERFUL CLASS'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa    \n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "local_file, sampling_rate = librosa.load('../data/sample.wav', sr=16000) # Downsample to 16kHz as the model was trained in\n",
    "\n",
    "input_values = processor(local_file, return_tensors=\"pt\", sampling_rate=sampling_rate).input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-demographic",
   "metadata": {},
   "source": [
    "## Image Captioning does not do THAT much better than ours :) \n",
    "https://huggingface.co/spaces/flax-community/image-captioning\n",
    "<img title=\"a title\" alt=\"Attention\" src=\"../images/ViT.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-jewel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "assumed-moldova",
   "metadata": {},
   "source": [
    "## Text to Image. Truly Horrifying :)\n",
    "https://huggingface.co/spaces/flax-community/dalle-mini\n",
    "<img title=\"a title\" alt=\"Attention\" src=\"../images/texttoimage.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-delhi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worth-infection",
   "metadata": {},
   "source": [
    "## Python code completion\n",
    "\n",
    "[Huggingface repo here](https://huggingface.co/Sentdex/GPyT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interpreted-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Sentdex/GPyT\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Sentdex/GPyT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excited-snake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "df = pd.read_csv('data/data/data\n"
     ]
    }
   ],
   "source": [
    "input_code = \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd\"\"\"  # I'd expect a read_csv here\n",
    "\n",
    "converted = input_code.replace(\"\\n\", \"<N>\")\n",
    "tokenized = tokenizer.encode(converted, return_tensors='pt')\n",
    "resp = model.generate(tokenized, max_length=tokenized.shape[1] + 10)  # 10 more tokens\n",
    "\n",
    "decoded = tokenizer.decode(resp[0])\n",
    "reformatted = decoded.replace(\"<N>\",\"\\n\")\n",
    "\n",
    "print(reformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-swaziland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-better",
   "metadata": {},
   "source": [
    "## Article Headline Generation\n",
    "\n",
    "[Huggingface repo here](https://huggingface.co/Michau/t5-base-en-generate-headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disciplinary-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Michau/t5-base-en-generate-headline\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Michau/t5-base-en-generate-headline\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exposed-exchange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Trump and First Lady Melania Test Positive for COVID-19</s>\n"
     ]
    }
   ],
   "source": [
    "article = '''\n",
    "Very early yesterday morning, the United States President Donald Trump reported he and his wife First Lady Melania Trump tested positive for COVID-19. Officials said the Trumps' 14-year-old son Barron tested negative as did First Family and Senior Advisors Jared Kushner and Ivanka Trump.\n",
    "Trump took to social media, posting at 12:54 am local time (0454 UTC) on Twitter, \"Tonight, [Melania] and I tested positive for COVID-19. We will begin our quarantine and recovery process immediately. We will get through this TOGETHER!\" Yesterday afternoon Marine One landed on the White House's South Lawn flying Trump to Walter Reed National Military Medical Center (WRNMMC) in Bethesda, Maryland.\n",
    "Reports said both were showing \"mild symptoms\". Senior administration officials were tested as people were informed of the positive test. Senior advisor Hope Hicks had tested positive on Thursday.\n",
    "Presidential physician Sean Conley issued a statement saying Trump has been given zinc, vitamin D, Pepcid and a daily Aspirin. Conley also gave a single dose of the experimental polyclonal antibodies drug from Regeneron Pharmaceuticals.\n",
    "According to official statements, Trump, now operating from the WRNMMC, is to continue performing his duties as president during a 14-day quarantine. In the event of Trump becoming incapacitated, Vice President Mike Pence could take over the duties of president via the 25th Amendment of the US Constitution. The Pence family all tested negative as of yesterday and there were no changes regarding Pence's campaign events.\n",
    "'''\n",
    "\n",
    "text =  \"headline: \" + article\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
    "input_ids = encoding[\"input_ids\"].to(device)\n",
    "attention_masks = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "beam_outputs = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    attention_mask = attention_masks,\n",
    "    max_length = 64,\n",
    "    num_beams = 3,\n",
    "    early_stopping = True,\n",
    ")\n",
    "\n",
    "result = tokenizer.decode(beam_outputs[0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21db7047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load env variables from a .env file | pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stock-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noma, Rated the Worldâs Best Restaurant, Is Closing Its Doors https://www.nytimes.com/2023/01/09/dining/noma-closing-rene-redzepi.html\n",
      "Biden Lawyers Found Classified Material at His Former Office https://www.nytimes.com/2023/01/09/us/politics/biden-classified-documents.html\n",
      "A Lecturer Showed a Painting of the Prophet Muhammad. She Lost Her Job. https://www.nytimes.com/2023/01/08/us/hamline-university-islam-prophet-muhammad.html\n",
      "House Narrowly Approves Rules Amid Concerns About McCarthyâs Concessions https://www.nytimes.com/2023/01/09/us/politics/house-rules-republicans-mccarthy.html\n",
      "Has Prince Harryâs Confessional Tour Run Its Course? https://www.nytimes.com/2023/01/09/books/prince-harry-book-royal-family.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Noma, Rated the Worldâs Best Restaurant, Is Closing Its Doors',\n",
       " 'https://www.nytimes.com/2023/01/09/dining/noma-closing-rene-redzepi.html')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from random import sample\n",
    "import os\n",
    "\n",
    "NYTIMES_KEY = os.environ.get('NYTIMES_KEY')\n",
    "\n",
    "results =  requests.get(f'https://api.nytimes.com/svc/mostpopular/v2/viewed/1.json?api-key={NYTIMES_KEY}').json()['results']\n",
    "\n",
    "for result in results[:5]:\n",
    "    print(result['title'], result['url'])\n",
    "\n",
    "article = results[0]\n",
    "\n",
    "article['title'], article['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "skilled-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_body = \"\"\"Erika LÃ³pez Prater, an adjunct professor at Hamline University, said she knew many Muslims have deeply held religious beliefs that prohibit depictions of the Prophet Muhammad. So last semester for a global art history class, she took many precautions before showing a 14th-century painting of Islamâs founder.\n",
    "\n",
    "In the syllabus, she warned that images of holy figures, including the Prophet Muhammad and the Buddha, would be shown in the course. She asked students to contact her with any concerns, and she said no one did.\n",
    "\n",
    "In class, she prepped students, telling them that in a few minutes, the painting would be displayed, in case anyone wanted to leave.\n",
    "\n",
    "Then Dr. LÃ³pez Prater showed the image â and lost her teaching gig.\n",
    "\n",
    "Officials at Hamline, a small, private university in St. Paul, Minn., with about 1,800 undergraduates, had tried to douse what they feared would become a runaway fire. Instead they ended up with what they had tried to avoid: a national controversy, which pitted advocates of academic liberty and free speech against Muslims who believe that showing the image of Prophet Muhammad is always sacrilegious.\n",
    "\n",
    "After Dr. LÃ³pez Prater showed the image, a senior in the class complained to the administration. Other Muslim students, not in the course, supported the student, saying the class was an attack on their religion. They demanded that officials take action.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fabulous-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"headline: \" + article_body\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_masks = encoding[\"attention_mask\"]\n",
    "\n",
    "beam_outputs = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    attention_mask = attention_masks,\n",
    "    max_length = input_ids.shape[1] + 15,\n",
    "    num_beams = 5,\n",
    "    early_stopping = True,\n",
    ")\n",
    "\n",
    "result = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "devoted-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Title\n",
      "==============\n",
      " Noma, Rated the Worldâs Best Restaurant, Is Closing Its Doors \n",
      "\n",
      "Generated Title\n",
      "==============\n",
      " Hamline University's Art History Professor Loses Teaching Job\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Title\\n==============\\n\", article['title'], \"\\n\\nGenerated Title\\n==============\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
