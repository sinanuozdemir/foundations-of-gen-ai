{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae6498-9a84-4309-b9d7-6c3201bc19e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0bd5aa-e05f-48da-9ddc-c13235868a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinanozdemir/Library/Python/3.9/lib/python/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/sinanozdemir/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sinanozdemir/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def get_cosine_similarity(embedding1, embedding2):\n",
    "    # Calculate cosine similarity (note: scipy's cosine function actually computes the distance, so we subtract from 1)\n",
    "    cos_sim = 1 - cosine(embedding1, embedding2)\n",
    "    return cos_sim\n",
    "\n",
    "# Initialize the model\n",
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence\", \"This is also an example sentence.\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = embed_model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3096113e-38b6-4a95-84bd-966807b2612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8140872363474145\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24953c6d-5641-480e-8c1f-fd13d0387f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b232f03-8dd1-4887-860d-82dd5cb2ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.42858588695526123\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I like this\", \"I hate this\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = embed_model.encode(sentences)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe201926-ea91-4cf0-846c-6bdb9b639c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c37299a-89c7-4f60-90a5-10c4bb543803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_word_embedding(sentence, word, model, tokenizer, model_type='bert'):\n",
    "    # Tokenize and encode the sentence\n",
    "    if model_type == 'gpt':\n",
    "        word = f' {word}'\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Find the index of the word (handling potential subword tokenization)\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    word_index = None\n",
    "    for i in range(len(tokens) - len(word_tokens) + 1):\n",
    "        if tokens[i:i + len(word_tokens)] == word_tokens:\n",
    "            word_index = i\n",
    "            break\n",
    "    if word_index is None:\n",
    "        raise ValueError(f\"Word '{word}' not found in the tokenized sentence.\")\n",
    "\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    # Extract the embedding for the specified word (for GPT models, take the last layer)\n",
    "    if model_type == 'bert':\n",
    "        word_embedding = output.last_hidden_state[0, word_index, :]\n",
    "    elif model_type == 'gpt':\n",
    "        word_embedding = output['last_hidden_state'][0, word_index, :]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "    \n",
    "    return word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03769993-e6ed-417c-833a-5a05f76c7493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinanozdemir/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained models and tokenizers\n",
    "\n",
    "# For BERT (auto-encoding)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# For GPT-2 (auto-regressive)\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "gpt_model = AutoModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f161f8d-ed4a-44f2-bbbf-5ca28f279ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Initial Embedding for 'bank': tensor([ 0.0894, -0.5583, -1.3665, -1.0918, -0.3904])\n",
      "GPT-2 Initial Embedding for 'bank': tensor([ 0.0457,  0.0819,  0.1375,  0.0381, -0.0269])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_initial_word_embedding(word, tokenizer, model, model_type='bert'):\n",
    "    if model_type == 'gpt':\n",
    "        word = f' {word}'\n",
    "    # Tokenize and encode the word\n",
    "    encoded_input = tokenizer(word, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Handling the case when a word is split into subwords\n",
    "    if len(tokens) > 3:  # Including special tokens [CLS], [SEP] for BERT or GPT-2\n",
    "        raise ValueError(\"The word was split into subwords. Please provide a single token.\")\n",
    "\n",
    "    # Extract the token index (excluding special tokens)\n",
    "    token_index = 1 if model_type == 'bert' else 0\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        if model_type == 'bert':\n",
    "            embeddings = model.embeddings(encoded_input['input_ids'])[0, token_index, :]\n",
    "        elif model_type == 'gpt':\n",
    "            # For GPT-2, manually apply the embedding layer\n",
    "            input_ids = encoded_input['input_ids']\n",
    "            embeddings = model.wte(input_ids)[0, token_index, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "\n",
    "    return embeddings\n",
    "    \n",
    "# Example word\n",
    "word = \"bank\"\n",
    "\n",
    "# Get initial embedding for BERT\n",
    "bert_initial_embedding = get_initial_word_embedding(word, bert_tokenizer, bert_model, 'bert')\n",
    "print(\"BERT Initial Embedding for '{}':\".format(word), bert_initial_embedding[:5])\n",
    "\n",
    "# Get initial embedding for GPT-2\n",
    "gpt_initial_embedding = get_initial_word_embedding(word, gpt_tokenizer, gpt_model, 'gpt')\n",
    "print(\"GPT-2 Initial Embedding for '{}':\".format(word), gpt_initial_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07c5af-87b6-41f2-b492-c6a6cc3b5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da4040c-c6ac-471e-8b56-94af7fdc165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.2764, -0.4860,  0.2104, -0.3106, -0.0630])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the river bank for a nice walk.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# Get BERT embedding for bank\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6707430-fba7-47f2-a769-1b7cb260a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BERT similarity to initial water/money embedding\n",
    "water_embedding = get_initial_word_embedding('water', bert_tokenizer, bert_model, 'bert')\n",
    "money_embedding = get_initial_word_embedding('money', bert_tokenizer, bert_model, 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d59d97-54c5-4c76-8f1a-3f711ef2b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to BERT(water): 0.06027549093840867\n",
      "Cosine Similarity to BERT(money): 0.004379517798154486\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to BERT(water):\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to BERT(money):\", get_cosine_similarity(embedding, money_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cff8d1e-4dd3-43be-b417-861583a7e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.7613, -0.3984, -0.1457, -0.1107,  1.2720])\n"
     ]
    }
   ],
   "source": [
    "# BERT embeddings for \"bank\" in relation to cash\n",
    "sentence = \"I went to the bank to get some cash out of savings.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# bank has a different embedding\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcf9e5f-aa0c-4e77-81c5-b2d5c8551497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to BERT(water): -0.0015438952866835276\n",
      "Cosine Similarity to BERT(money): 0.0618748685479007\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to BERT(water):\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to BERT(money):\", get_cosine_similarity(embedding, money_embedding))\n",
    "\n",
    "# similarity went down compared to water and up for money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7c6a-bd5a-4683-9269-015824c68212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92a238f-72da-4bc2-9917-f3cc41c4be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gpt, position matters for embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97117d33-6282-41ac-899a-b9d21ea46312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Embedding for 'bank' in relation to cash: tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank to get some cash out of savings\"\n",
    "word = \"bank\"\n",
    "\n",
    "# Get embedding\n",
    "bank_gpt_embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer, model_type='gpt')\n",
    "print(\"GPT Embedding for '{}' in relation to cash:\".format(word), bank_gpt_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126b8c6d-f135-4f9c-bf68-d316fc3b61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Embedding for 'bank' in relation to water: tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank of the river for a nice walk.\"\n",
    "word = \"bank\"\n",
    "\n",
    "river_gpt_embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer, model_type='gpt')\n",
    "print(\"GPT Embedding for '{}' in relation to water:\".format(word), river_gpt_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c7a00e-ccb4-49a0-81d6-97cb9fbb522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They are the same embedding!!!\n",
    "# Same embedding for \" bank\" because all words are the same before \" bank\"\n",
    "(bank_gpt_embedding == river_gpt_embedding).all().item()\n",
    "# Note I specifically designed the sentences to have the EXACT same tokens preceding bank.\n",
    "#  only the tokens after bank are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4928-4c86-4c70-90f0-8b67d2feac03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b199b1-f2ef-48d9-9b8b-059f6afcc501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29295ed2-468e-4d7c-88dc-0ac8a32d7601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa74cc8-53ea-4730-b4a7-15c3b6c23f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (/usr/bin/python3)",
   "language": "python",
   "name": "my_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
